{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import random_split, Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from torchvision.datasets import ImageFolder \n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! Training on GPU...\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print('CUDA is available! Training on GPU...')\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print('CUDA is not available. Training on CPU...')\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 336\n",
      "Number of validation samples: 84\n",
      "Number of test samples: 20\n",
      "Class names: ['align_engine_output', 'calibrate_distributor', 'chart_course', 'clean_o2_filter', 'clean_vent', 'clear_asteroids', 'divert_power', 'empty_garbage', 'fix_wiring', 'fuel_engines', 'inspect_sample', 'prime_shields', 'stabilize_steering', 'start_reactor', 'swipe_card', 'unlock_manifolds', 'upload_data']\n"
     ]
    }
   ],
   "source": [
    "train_val_path = r\"..\\images\\train_val_images\"\n",
    "test_path = r\"..\\images\\test_images\"\n",
    "\n",
    "num_classes = 17\n",
    "\n",
    "# Load the dataset\n",
    "baseDataset = ImageFolder(train_val_path, transform=transforms.ToTensor())\n",
    "\n",
    "#Augment and combine the datasets\n",
    "brighten_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=[1.25, 1.75]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "dim_transform = transforms.Compose([\n",
    "    transforms.ColorJitter(brightness=[0.25, 0.75]),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "brightenedDataset = ImageFolder(train_val_path, transform=brighten_transform)\n",
    "dimmedDataset = ImageFolder(train_val_path, transform=dim_transform)\n",
    "combinedDataset = baseDataset + brightenedDataset + dimmedDataset\n",
    "\n",
    "# Define the split ratio\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.2\n",
    "\n",
    "# Calculate the number of samples for train and validation sets\n",
    "num_train = int(len(combinedDataset) * train_ratio)\n",
    "num_val = len(combinedDataset) - num_train\n",
    "\n",
    "# Split the dataset\n",
    "train_set, valid_set = torch.utils.data.random_split(combinedDataset, [num_train, num_val])\n",
    "\n",
    "# Load the test set\n",
    "test_set = ImageFolder(test_path, transform=transforms.ToTensor())\n",
    "\n",
    "# Get class names\n",
    "class_names = baseDataset.classes\n",
    "\n",
    "print(f\"Number of training samples: {len(train_set)}\")\n",
    "print(f\"Number of validation samples: {len(valid_set)}\")\n",
    "print(f\"Number of test samples: {len(test_set)}\")\n",
    "print(f\"Class names: {class_names}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.name = \"resnetclassifier\"\n",
    "\n",
    "        # Load the pre-trained ResNet model\n",
    "        resnet = models.resnet152(weights=models.ResNet152_Weights.IMAGENET1K_V1)\n",
    "\n",
    "        # Replace the last fully connected layer\n",
    "        num_features = resnet.fc.in_features\n",
    "        self.features = nn.Sequential(*list(resnet.children())[:-1])\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_features,num_classes),\n",
    "            # nn.Softmax(dim=1)  #single label \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(model, loader):\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "            imgs = imgs.to(device)\n",
    "            output = model(imgs)\n",
    "\n",
    "            _, predicted = torch.max(output, 1)\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    #-average F1 score\n",
    "    micro_f1 = f1_score(all_labels, all_predictions, average='micro')\n",
    "\n",
    "    return micro_f1\n",
    "\n",
    "\n",
    "def get_model_name(name, batch_size, learning_rate, decay_rate, epoch):\n",
    "    path = \"model_{0}_bs{1}_lr{2}_dr{3}_epoch{4}\".format(name, batch_size, learning_rate, decay_rate, epoch)\n",
    "\n",
    "    return path\n",
    "\n",
    "\n",
    "def evaluate(model, loader, criterion):\n",
    "    total_loss = 0\n",
    "    i = 0\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for imgs, labels in loader:\n",
    "\n",
    "            imgs = imgs.cuda().to(device) # Move the input tensors to the desired device\n",
    "            labels = labels.cuda().to(device)\n",
    "\n",
    "            #labels = labels.float()\n",
    "            out = model(imgs)  # forward pass\n",
    "            loss = criterion(out, labels)  # compute the total loss\n",
    "            total_loss += loss.item()\n",
    "            i += 1\n",
    "\n",
    "            \n",
    "    model.train()  # Set the model back to training mode\n",
    "\n",
    "    loss = float(total_loss) / (i)\n",
    "    return loss\n",
    "\n",
    "def plot_training_curve(path):\n",
    "    train_acc = np.loadtxt(\"{}_train_acc.csv\".format(path), delimiter=',')  # Specify delimiter as ','\n",
    "    val_acc = np.loadtxt(\"{}_val_acc.csv\".format(path), delimiter=',')  # Specify delimiter as ','\n",
    "\n",
    "    plt.title(\"Train vs Validation Accuracy\")\n",
    "    n = len(train_acc)  # number of epochs\n",
    "    plt.plot(range(1, n + 1), train_acc, label=\"Train\")\n",
    "    plt.plot(range(1, n + 1), val_acc, label=\"Validation\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_set, valid_set, batch_size=1, num_epochs=5, learning_rate=1e-3, decay_rate=0.9):\n",
    "    torch.manual_seed(1000)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train_loader = DataLoader(train_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(valid_set, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "    print(\"Length of train_loader\",len(train_loader))\n",
    "    print(\"Length of val_loader\",len(val_loader))\n",
    "\n",
    "    train_acc, val_acc, train_loss, val_loss = [], [], [], []\n",
    "    i=0.0\n",
    "\n",
    "    start_time = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        total_train_loss = 0.0\n",
    "\n",
    "        # Learning rate decay calculation\n",
    "        current_learning_rate = learning_rate / (1 + decay_rate * epoch)\n",
    "\n",
    "        # Update optimizer learning rate\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = current_learning_rate\n",
    "\n",
    "        for imgs, labels in train_loader:\n",
    "            if torch.cuda.is_available():\n",
    "                imgs = imgs.cuda().to(device)\n",
    "                labels = labels.cuda().to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    " \n",
    "            out = model(imgs)\n",
    "            \n",
    "            loss = criterion(out, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            i+=1\n",
    "\n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        train_epoch_acc = get_f1_score(model, train_loader)\n",
    "        train_acc.append(train_epoch_acc)\n",
    "\n",
    "        val_epoch_acc = get_f1_score(model, val_loader)\n",
    "        val_acc.append(val_epoch_acc)\n",
    "\n",
    "        train_loss.append(total_train_loss / (i))\n",
    "        val_loss.append(evaluate(model, val_loader, criterion))\n",
    "\n",
    "        try:\n",
    "            print((\"Epoch {}: Train Acc: {:.4f}, Train Loss: {:.4f} | \" + \"Validation Acc: {:.4f}, Validation Loss: {:.4f}\").format(\n",
    "            epoch + 1,\n",
    "            train_acc[epoch],\n",
    "            train_loss[epoch],\n",
    "            val_acc[epoch],\n",
    "            val_loss[epoch]))\n",
    "        except Exception as e:\n",
    "            print(\"An error occurred during printing:\", e)\n",
    "        \n",
    "        \n",
    "        if(epoch % 5) == 4 or epoch == 0:\n",
    "            model_path = get_model_name(model.name, batch_size, learning_rate, decay_rate, epoch)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "        \n",
    "    print('Finished Training')\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Total time elapsed: {:.2f} seconds\".format(elapsed_time))\n",
    "\n",
    "    try:\n",
    "        with open(\"{}_train_acc.csv\".format(model_path), \"w\", newline=\"\") as f_train_acc:\n",
    "            writer_train_acc = csv.writer(f_train_acc)\n",
    "            writer_train_acc.writerow(train_acc)\n",
    "        with open(\"{}_val_acc.csv\".format(model_path), \"w\", newline=\"\") as f_val_acc:\n",
    "            writer_val_acc = csv.writer(f_val_acc)\n",
    "            writer_val_acc.writerow(val_acc)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred while saving the results:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "Length of train_loader 84\n",
      "Length of val_loader 21\n",
      "Epoch 1: Train Acc: 0.9762, Train Loss: 0.0031 | Validation Acc: 0.9881, Validation Loss: 0.0286\n",
      "Epoch 2: Train Acc: 0.9911, Train Loss: 0.0009 | Validation Acc: 1.0000, Validation Loss: 0.0020\n",
      "Epoch 3: Train Acc: 0.9970, Train Loss: 0.0001 | Validation Acc: 1.0000, Validation Loss: 0.0010\n",
      "Epoch 4: Train Acc: 1.0000, Train Loss: 0.0000 | Validation Acc: 1.0000, Validation Loss: 0.0003\n",
      "Epoch 5: Train Acc: 1.0000, Train Loss: 0.0000 | Validation Acc: 1.0000, Validation Loss: 0.0007\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m resnetmodel\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m      6\u001b[0m path_to_resnet \u001b[38;5;241m=\u001b[39m get_model_name(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresnetclassifier\u001b[39m\u001b[38;5;124m\"\u001b[39m,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m,learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, decay_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5\u001b[39m, epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m9\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresnetmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecay_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[6], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, train_set, valid_set, batch_size, num_epochs, learning_rate, decay_rate)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m imgs, labels \u001b[38;5;129;01min\u001b[39;00m train_loader:\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available():\n\u001b[1;32m---> 27\u001b[0m         imgs \u001b[38;5;241m=\u001b[39m \u001b[43mimgs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     28\u001b[0m         labels \u001b[38;5;241m=\u001b[39m labels\u001b[38;5;241m.\u001b[39mcuda()\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     30\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "resnetmodel = ResNet(num_classes).cuda()\n",
    "print(torch.cuda.is_available())\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "resnetmodel.train()\n",
    "path_to_resnet = get_model_name(\"resnetclassifier\",batch_size=4,learning_rate=1e-4, decay_rate=0.5, epoch=9)\n",
    "train(resnetmodel,train_set, valid_set, batch_size=4, num_epochs=10, learning_rate=1e-4, decay_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of test_loader 5\n",
      "The final test accuracy of our model is: 100.0 %\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_set, batch_size=4, shuffle=True, num_workers=0)\n",
    "print(\"Length of test_loader\",len(test_loader))\n",
    "\n",
    "resnetmodel.eval()\n",
    "test_accuracy = get_f1_score(resnetmodel, test_loader)\n",
    "print(\"The final test accuracy of our model is:\", test_accuracy*100,\"%\")\n",
    "# plot_training_curve(path_to_resnet)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
